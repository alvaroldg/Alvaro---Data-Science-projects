{"cells":[{"cell_type":"code","execution_count":null,"id":"04a7788a","metadata":{"id":"04a7788a"},"outputs":[],"source":["#INSTALACIÓN DE LIBRERIAS\n","!pip install Torch==1.8.1\n","!pip install TorchVision\n","!pip install pickle\n","#IMPORTS\n","import os\n","import shutil\n","import cv2\n","import numpy as np\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import ParameterGrid\n","from sklearn.preprocessing import MinMaxScaler\n","import pickle"]},{"cell_type":"code","execution_count":null,"id":"559f2859","metadata":{"id":"559f2859"},"outputs":[],"source":["import pickle\n","import random\n","\n","ruta_train = 'C:\\\\Users\\\\Angel\\\\Downloads\\\\IDC_train.dat'\n","ruta_test = 'C:\\\\Users\\\\Angel\\\\Downloads\\\\IDC_test.dat'\n","\n","# Cargar el archivo de entrenamiento\n","with open(ruta_train, 'rb') as f:\n","    (X_train, y_train) = pickle.load(f)\n","\n","# Cargar el archivo de prueba\n","with open(ruta_test, 'rb') as f:\n","    (X_test, y_test) = pickle.load(f)\n","\n","# Obtener el 30% de los datos de entrenamiento\n","total_samples_train = len(X_train)\n","num_samples_train = int(0.3 * total_samples_train)\n","random_indices_train = random.sample(range(total_samples_train), num_samples_train)\n","X_train = [X_train[i] for i in random_indices_train]\n","y_train = [y_train[i] for i in random_indices_train]\n","\n","# Obtener el 30% de los datos de prueba\n","total_samples_test = len(X_test)\n","num_samples_test = int(0.3 * total_samples_test)\n","random_indices_test = random.sample(range(total_samples_test), num_samples_test)\n","X_test = [X_test[i] for i in random_indices_test]\n","y_test = [y_test[i] for i in random_indices_test]\n","\n","# Realizar cualquier otra operación necesaria con los datos cargados\n"]},{"cell_type":"code","execution_count":null,"id":"0ca385fe","metadata":{"id":"0ca385fe"},"outputs":[],"source":["# Import necessary libraries\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import ParameterGrid\n","\n","# Define custom dataset\n","class CustomDataset(Dataset):\n","    def __init__(self, X, y):\n","        self.X = X\n","        self.y = y\n","\n","    def __len__(self):\n","        return len(self.X)\n","\n","    def __getitem__(self, idx):\n","        return self.X[idx], self.y[idx]\n","\n","# Create train and test datasets\n","train_dataset = CustomDataset(X_train, y_train)\n","test_dataset = CustomDataset(X_test, y_test)\n","\n","# Define the model architecture\n","class Model(nn.Module):\n","    def __init__(self, num_neurons):\n","        super(Model, self).__init__()\n","        self.conv1 = nn.Conv2d(3, num_neurons, 3)\n","        self.conv2 = nn.Conv2d(num_neurons, num_neurons*2, 3)\n","        self.conv3 = nn.Conv2d(num_neurons*2, num_neurons*4, 3)\n","        self.conv4 = nn.Conv2d(num_neurons*4, num_neurons*8, 3)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.fc1 = nn.Linear(num_neurons*8, num_neurons)  # Asume que después de cuatro convoluciones y max pooling, la dimensión es num_neurons * 8 * 3 * 3\n","        self.fc2 = nn.Linear(num_neurons, 1)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = self.pool(F.relu(self.conv2(x)))\n","        x = self.pool(F.relu(self.conv3(x)))\n","        x = self.pool(F.relu(self.conv4(x)))\n","        x = x.view(-1, self.num_flat_features(x))\n","        x = F.relu(self.fc1(x))\n","        x = self.sigmoid(self.fc2(x))\n","        return x\n","\n","    def num_flat_features(self, x):\n","        size = x.size()[1:]  # all dimensions except the batch dimension\n","        num_features = 1\n","        for s in size:\n","            num_features *= s\n","        return num_features\n","\n","# Define the function to create the model\n","def crear_modelo(num_neurons):\n","    print(\"CREAR MODELO\", num_neurons)\n","    model = Model(num_neurons)\n","    criterion = nn.BCELoss()\n","    optimizer = optim.Adam(model.parameters())\n","    return model, criterion, optimizer\n","\n","# Define the checkpoint directory\n","checkpoint_dir = 'D:/Master/TFM/Checkpoints'\n","\n","# Create checkpoint directory if it doesn't exist\n","os.makedirs(checkpoint_dir, exist_ok=True)\n","\n","def save_ckpt(model, optimizer, epoch, num_neurons, checkpoint_dir):\n","    save_dir = os.path.join(checkpoint_dir, \"checkpoint_{:04d}_{}.pth\".format(epoch, num_neurons))\n","\n","    cp = {\n","        'model': model.state_dict(),\n","        'optimizer': optimizer.state_dict(),\n","        'epoch': epoch,\n","    }\n","\n","    torch.save(cp, save_dir)\n","    print(\"Saved checkpoint into {}\".format(save_dir))\n","\n","\n","def load_ckpt(checkpoint_dir, num_neurons):\n","    last_epoch = 0\n","    checkpoint_file = ''\n","\n","    for file in os.listdir(checkpoint_dir):\n","        if file.endswith('{}.pth'.format(num_neurons)):\n","            epoch_number = int(file.split('_')[1])\n","            if epoch_number > last_epoch:\n","                last_epoch = epoch_number\n","                checkpoint_file = file\n","\n","    if last_epoch == 0:\n","        return None, 0\n","    else:\n","        print(\"Loaded checkpoint\", os.path.join(checkpoint_dir, checkpoint_file))\n","        checkpoint = torch.load(os.path.join(checkpoint_dir, checkpoint_file))\n","        return checkpoint, checkpoint['epoch']\n","\n","# Define the grid of parameters\n","param_grid = {\n","    'num_neurons': [10, 20, 30],\n","}\n","\n","# Perform grid search\n","best_accuracy = 0.0\n","best_params = None\n","\n","for params in ParameterGrid(param_grid):\n","    print(\"Using {} neurons\".format(params['num_neurons']))\n","    model, criterion, optimizer = crear_modelo(params['num_neurons'])\n","    checkpoint, start_epoch = load_ckpt(checkpoint_dir, params['num_neurons'])\n","    if checkpoint is not None:\n","        model.load_state_dict(checkpoint['model'])\n","        optimizer.load_state_dict(checkpoint['optimizer'])\n","\n","    train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n","    test_loader = DataLoader(test_dataset, batch_size=10, shuffle=False)\n","\n","    for epoch in range(start_epoch, start_epoch + 10):\n","        model.train()\n","        for inputs, labels in train_loader:\n","            optimizer.zero_grad()\n","            inputs = inputs.permute((0,3,1,2))\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels.float().unsqueeze(1))\n","            loss.backward()\n","            optimizer.step()\n","\n","        save_ckpt(model, optimizer, epoch + 1, params['num_neurons'], checkpoint_dir) # Save the checkpoint\n","\n","        model.eval()\n","        correct = 0\n","        total = 0\n","        with torch.no_grad():\n","            for inputs, labels in test_loader:\n","                inputs = inputs.permute((0,3,1,2))\n","                outputs = model(inputs)\n","                predicted = (outputs >= 0.5).squeeze().long()\n","                total += labels.size(0)\n","                correct += (predicted == labels).sum().item()\n","\n","        accuracy = correct / total\n","        print(\"Epoch: {}, Accuracy: {}\".format(epoch + 1, accuracy))\n","        if accuracy > best_accuracy:\n","            best_accuracy = accuracy\n","            best_params = params\n","\n","print(\"Best Accuracy:\", best_accuracy)\n","print(\"Best Parameters:\", best_params)\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}