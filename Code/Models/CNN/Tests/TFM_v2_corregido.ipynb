{"cells":[{"cell_type":"code","execution_count":null,"id":"ea5fdff6","metadata":{"id":"ea5fdff6","executionInfo":{"status":"ok","timestamp":1687198957616,"user_tz":-120,"elapsed":8108,"user":{"displayName":"Álvaro Ladrón de Guevara Garcés","userId":"07215819297576337673"}},"outputId":"c93ed649-4a21-43ff-816a-ed658160c6a5","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","\u001b[31mERROR: Could not find a version that satisfies the requirement Torch==1.8.1 (from versions: 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0, 2.0.1)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for Torch==1.8.1\u001b[0m\u001b[31m\n","\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: TorchVision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from TorchVision) (1.22.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from TorchVision) (2.27.1)\n","Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (from TorchVision) (2.0.1+cu118)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from TorchVision) (8.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->TorchVision) (3.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->TorchVision) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->TorchVision) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->TorchVision) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->TorchVision) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->TorchVision) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->TorchVision) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->TorchVision) (16.0.5)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->TorchVision) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->TorchVision) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->TorchVision) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->TorchVision) (3.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->TorchVision) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->TorchVision) (1.3.0)\n"]}],"source":["#INSTALACIÓN DE LIBRERIAS\n","!pip install Torch==1.8.1\n","!pip install TorchVision"]},{"cell_type":"code","execution_count":null,"id":"a0612e71","metadata":{"id":"a0612e71"},"outputs":[],"source":["#IMPORTS\n","import os\n","import shutil\n","import cv2"]},{"cell_type":"code","execution_count":null,"id":"b4afde10","metadata":{"id":"b4afde10","executionInfo":{"status":"error","timestamp":1687200534340,"user_tz":-120,"elapsed":251,"user":{"displayName":"Álvaro Ladrón de Guevara Garcés","userId":"07215819297576337673"}},"outputId":"98592dae-6db6-44a8-85b5-f93f41c1d625","colab":{"base_uri":"https://localhost:8080/","height":244}},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-3957d5fffe0c>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Para cada archivo en la subcarpeta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mnombre_archivo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubcarpeta_ruta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;31m# Comprobar si el archivo es una imagen (esto dependerá de las extensiones de archivo de tus imágenes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnombre_archivo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:Master\\\\TFM\\\\IDC_regular_ps50_idx5\\\\00Prueba2/0'"]}],"source":["import os\n","import cv2\n","\n","# Ruta de la carpeta que contiene las imágenes\n","ruta_carpeta = r'D:\\Master\\TFM\\IDC_regular_ps50_idx5\\00Prueba2'\n","\n","# Lista para almacenar los arrays de las imágenes\n","listado_arrays_imagenes = []\n","listado_arrays_etiquetas = []\n","\n","# Recorrer las subcarpetas '0' y '1'\n","for subcarpeta in ['0', '1']:\n","    subcarpeta_ruta = os.path.join(ruta_carpeta, subcarpeta)\n","\n","    # Para cada archivo en la subcarpeta\n","    for nombre_archivo in os.listdir(subcarpeta_ruta):\n","        # Comprobar si el archivo es una imagen (esto dependerá de las extensiones de archivo de tus imágenes)\n","        if nombre_archivo.endswith('.png'):\n","            # Construir la ruta completa del archivo\n","            ruta_archivo = os.path.join(subcarpeta_ruta, nombre_archivo)\n","\n","            # Leer la imagen y convertirla a un array\n","            img = cv2.imread(ruta_archivo)\n","            # Añadir el array a la lista\n","            listado_arrays_imagenes.append(img)\n","            # Añadir la etiqueta correspondiente a la lista de etiquetas\n","            listado_arrays_etiquetas.append(int(subcarpeta))\n"]},{"cell_type":"code","execution_count":null,"id":"7451809d","metadata":{"id":"7451809d"},"outputs":[],"source":["import numpy as np\n","\n","# Convierte listado_arrays_etiquetas a numpy array\n","etiquetas = np.array(listado_arrays_etiquetas)\n","\n","# Obtén los índices de las imágenes con etiqueta 0 y selecciona los primeros 5000\n","indices_0 = np.where(etiquetas == 0)[0][:500]\n","\n","# Haz lo mismo para las imágenes con etiqueta 1\n","indices_1 = np.where(etiquetas == 1)[0][:500]\n","\n","# Concatena los índices de las imágenes de ambas etiquetas\n","indices = np.concatenate([indices_0, indices_1])\n","\n","# Utiliza los índices para seleccionar las imágenes y etiquetas correspondientes\n","listado_arrays_imagenes = [listado_arrays_imagenes[i] for i in indices]\n","listado_arrays_etiquetas = [listado_arrays_etiquetas[i] for i in indices]\n"]},{"cell_type":"code","execution_count":null,"id":"29bf8788","metadata":{"id":"29bf8788"},"outputs":[],"source":["import numpy as np\n","from sklearn.preprocessing import MinMaxScaler\n","\n","# Asumimos que la lista 'listado_arrays_imagenes' existe y contiene las matrices de imágenes\n","\n","# Verificar la forma de las matrices\n","shapes = set(img.shape for img in listado_arrays_imagenes)\n","if len(shapes) > 1:\n","    # Realizar operación de ajuste en las matrices para que tengan la misma forma\n","    max_shape = max(shapes, key=lambda x: np.prod(x))\n","    listado_arrays_imagenes = [np.pad(img, [(0, max_shape[0]-img.shape[0]),\n","                                           (0, max_shape[1]-img.shape[1]),\n","                                           (0, max_shape[2]-img.shape[2])],\n","                                      mode='constant', constant_values=0)\n","                               for img in listado_arrays_imagenes]\n","\n","# Convertir la lista de imágenes en una matriz 4D\n","imagenes = np.stack(listado_arrays_imagenes)\n","\n","# Obtener las dimensiones de las imágenes\n","num_imagenes, altura, anchura, canales = imagenes.shape\n","\n","# Reshape para que las imágenes sean 2D\n","imagenes_2d = imagenes.reshape(num_imagenes, -1)\n","\n","# Crear una instancia del escalador MinMaxScaler\n","scaler = MinMaxScaler()\n","\n","# Aplicar el escalado a las imágenes\n","imagenes_escaladas = scaler.fit_transform(imagenes_2d)\n","\n","# Reshape de nuevo a las dimensiones originales de las imágenes\n","imagenes_escaladas = imagenes_escaladas.reshape(num_imagenes, altura, anchura, canales)\n"]},{"cell_type":"code","execution_count":null,"id":"4f91b79d","metadata":{"id":"4f91b79d","outputId":"cfe52b04-5c18-4000-9ea6-c30b4ae4bb90"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cantidad de etiquetas 1: 18\n","Cantidad de etiquetas 0: 24\n"]}],"source":["# Contar las etiquetas 1\n","count_1 = listado_arrays_etiquetas.count(1)\n","print(f'Cantidad de etiquetas 1: {count_1}')\n","\n","# Contar las etiquetas 0\n","count_0 = listado_arrays_etiquetas.count(0)\n","print(f'Cantidad de etiquetas 0: {count_0}')\n"]},{"cell_type":"code","execution_count":null,"id":"7db53521","metadata":{"id":"7db53521","outputId":"6837b742-f3bb-416f-b1a4-9e60ff25dd27"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using 10 neurons\n","CREAR MODELO 10\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0001_10.pth\n","Epoch: 1, Accuracy: 0.4444444444444444\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0002_10.pth\n","Epoch: 2, Accuracy: 0.4444444444444444\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0003_10.pth\n","Epoch: 3, Accuracy: 0.4444444444444444\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0004_10.pth\n","Epoch: 4, Accuracy: 0.4444444444444444\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0005_10.pth\n","Epoch: 5, Accuracy: 0.4444444444444444\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0006_10.pth\n","Epoch: 6, Accuracy: 0.4444444444444444\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0007_10.pth\n","Epoch: 7, Accuracy: 0.4444444444444444\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0008_10.pth\n","Epoch: 8, Accuracy: 0.4444444444444444\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0009_10.pth\n","Epoch: 9, Accuracy: 0.4444444444444444\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0010_10.pth\n","Epoch: 10, Accuracy: 0.4444444444444444\n","Using 20 neurons\n","CREAR MODELO 20\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0001_20.pth\n","Epoch: 1, Accuracy: 0.5555555555555556\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0002_20.pth\n","Epoch: 2, Accuracy: 0.5555555555555556\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0003_20.pth\n","Epoch: 3, Accuracy: 0.5555555555555556\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0004_20.pth\n","Epoch: 4, Accuracy: 0.5555555555555556\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0005_20.pth\n","Epoch: 5, Accuracy: 0.5555555555555556\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0006_20.pth\n","Epoch: 6, Accuracy: 0.5555555555555556\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0007_20.pth\n","Epoch: 7, Accuracy: 0.5555555555555556\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0008_20.pth\n","Epoch: 8, Accuracy: 0.5555555555555556\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0009_20.pth\n","Epoch: 9, Accuracy: 0.5555555555555556\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0010_20.pth\n","Epoch: 10, Accuracy: 0.5555555555555556\n","Using 30 neurons\n","CREAR MODELO 30\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0001_30.pth\n","Epoch: 1, Accuracy: 0.5555555555555556\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0002_30.pth\n","Epoch: 2, Accuracy: 0.5555555555555556\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0003_30.pth\n","Epoch: 3, Accuracy: 0.5555555555555556\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0004_30.pth\n","Epoch: 4, Accuracy: 0.5555555555555556\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0005_30.pth\n","Epoch: 5, Accuracy: 0.5555555555555556\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0006_30.pth\n","Epoch: 6, Accuracy: 0.5555555555555556\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0007_30.pth\n","Epoch: 7, Accuracy: 0.5555555555555556\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0008_30.pth\n","Epoch: 8, Accuracy: 0.5555555555555556\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0009_30.pth\n","Epoch: 9, Accuracy: 0.5555555555555556\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0010_30.pth\n","Epoch: 10, Accuracy: 0.5555555555555556\n","Using 40 neurons\n","CREAR MODELO 40\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0001_40.pth\n","Epoch: 1, Accuracy: 0.5555555555555556\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0002_40.pth\n","Epoch: 2, Accuracy: 0.5555555555555556\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0003_40.pth\n","Epoch: 3, Accuracy: 0.5555555555555556\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0004_40.pth\n","Epoch: 4, Accuracy: 0.5555555555555556\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0005_40.pth\n","Epoch: 5, Accuracy: 0.5555555555555556\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0006_40.pth\n","Epoch: 6, Accuracy: 0.5555555555555556\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0007_40.pth\n","Epoch: 7, Accuracy: 0.5555555555555556\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0008_40.pth\n","Epoch: 8, Accuracy: 0.5555555555555556\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0009_40.pth\n","Epoch: 9, Accuracy: 0.5555555555555556\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0010_40.pth\n","Epoch: 10, Accuracy: 0.5555555555555556\n","Using 50 neurons\n","CREAR MODELO 50\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0001_50.pth\n","Epoch: 1, Accuracy: 0.5555555555555556\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0002_50.pth\n","Epoch: 2, Accuracy: 0.5555555555555556\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0003_50.pth\n","Epoch: 3, Accuracy: 0.5555555555555556\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0004_50.pth\n","Epoch: 4, Accuracy: 0.5555555555555556\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0005_50.pth\n","Epoch: 5, Accuracy: 0.5555555555555556\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0006_50.pth\n","Epoch: 6, Accuracy: 0.5555555555555556\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0007_50.pth\n","Epoch: 7, Accuracy: 0.5555555555555556\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0008_50.pth\n","Epoch: 8, Accuracy: 0.5555555555555556\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0009_50.pth\n","Epoch: 9, Accuracy: 0.5555555555555556\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0010_50.pth\n","Epoch: 10, Accuracy: 0.5555555555555556\n","Using 100 neurons\n","CREAR MODELO 100\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0001_100.pth\n","Epoch: 1, Accuracy: 0.4444444444444444\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0002_100.pth\n","Epoch: 2, Accuracy: 0.4444444444444444\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0003_100.pth\n","Epoch: 3, Accuracy: 0.4444444444444444\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0004_100.pth\n","Epoch: 4, Accuracy: 0.4444444444444444\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0005_100.pth\n","Epoch: 5, Accuracy: 0.4444444444444444\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0006_100.pth\n","Epoch: 6, Accuracy: 0.4444444444444444\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0007_100.pth\n","Epoch: 7, Accuracy: 0.4444444444444444\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0008_100.pth\n","Epoch: 8, Accuracy: 0.4444444444444444\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0009_100.pth\n","Epoch: 9, Accuracy: 0.4444444444444444\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0010_100.pth\n","Epoch: 10, Accuracy: 0.4444444444444444\n","Best Accuracy: 0.5555555555555556\n","Best Parameters: {'num_neurons': 20}\n"]}],"source":["# Import necessary libraries\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import ParameterGrid\n","\n","# Convert lists to tensors\n","imagenes = torch.stack([torch.Tensor(i) for i in imagenes])\n","etiquetas = torch.tensor(listado_arrays_etiquetas)\n","\n","# Split data into training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(imagenes, etiquetas, test_size=0.2, random_state=42)\n","\n","# Define custom dataset\n","class CustomDataset(Dataset):\n","    def __init__(self, X, y):\n","        self.X = X\n","        self.y = y\n","\n","    def __len__(self):\n","        return len(self.X)\n","\n","    def __getitem__(self, idx):\n","        return self.X[idx], self.y[idx]\n","\n","# Create train and test datasets\n","train_dataset = CustomDataset(X_train, y_train)\n","test_dataset = CustomDataset(X_test, y_test)\n","\n","# Define the model architecture\n","class Model(nn.Module):\n","    def __init__(self, num_neurons):\n","        super(Model, self).__init__()\n","        self.conv1 = nn.Conv2d(3, num_neurons, 3)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.fc = nn.Linear(num_neurons*24*24, 1)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = x.reshape(-1, self.num_flat_features(x))\n","        x = self.sigmoid(self.fc(x))\n","        return x\n","\n","    def num_flat_features(self, x):\n","        size = x.size()[1:]  # all dimensions except the batch dimension\n","        num_features = 1\n","        for s in size:\n","            num_features *= s\n","        return num_features\n","\n","# Define the function to create the model\n","def crear_modelo(num_neurons):\n","    print(\"CREAR MODELO\", num_neurons)\n","    model = Model(num_neurons)\n","    criterion = nn.BCELoss()\n","    optimizer = optim.Adam(model.parameters())\n","    return model, criterion, optimizer\n","\n","# Define the checkpoint directory\n","checkpoint_dir = 'D:/Master/TFM/Checkpoints'\n","\n","# Create checkpoint directory if it doesn't exist\n","os.makedirs(checkpoint_dir, exist_ok=True)\n","\n","def save_ckpt(model, optimizer, epoch, num_neurons, checkpoint_dir):\n","    save_dir = os.path.join(checkpoint_dir, \"checkpoint_{:04d}_{}.pth\".format(epoch, num_neurons))\n","\n","    cp = {\n","        'model': model.state_dict(),\n","        'optimizer': optimizer.state_dict(),\n","        'epoch': epoch,\n","    }\n","\n","    torch.save(cp, save_dir)\n","    print(\"Saved checkpoint into {}\".format(save_dir))\n","\n","\n","def load_ckpt(checkpoint_dir, num_neurons):\n","    last_epoch = 0\n","    checkpoint_file = ''\n","\n","    for file in os.listdir(checkpoint_dir):\n","        if file.endswith('{}.pth'.format(num_neurons)):\n","            epoch_number = int(file.split('_')[1])\n","            if epoch_number > last_epoch:\n","                last_epoch = epoch_number\n","                checkpoint_file = file\n","\n","    if last_epoch == 0:\n","        return None, 0\n","    else:\n","        print(\"Loaded checkpoint\", os.path.join(checkpoint_dir, checkpoint_file))\n","        checkpoint = torch.load(os.path.join(checkpoint_dir, checkpoint_file))\n","        return checkpoint, checkpoint['epoch']\n","\n","# Define the grid of parameters\n","param_grid = {\n","    'num_neurons': [10, 20, 30, 40, 50,100],\n","}\n","\n","# Perform grid search\n","best_accuracy = 0.0\n","best_params = None\n","\n","for params in ParameterGrid(param_grid):\n","    print(\"Using {} neurons\".format(params['num_neurons']))\n","    model, criterion, optimizer = crear_modelo(params['num_neurons'])\n","    checkpoint, start_epoch = load_ckpt(checkpoint_dir, params['num_neurons'])\n","    if checkpoint is not None:\n","        model.load_state_dict(checkpoint['model'])\n","        optimizer.load_state_dict(checkpoint['optimizer'])\n","\n","    train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n","    test_loader = DataLoader(test_dataset, batch_size=10, shuffle=False)\n","\n","    for epoch in range(start_epoch, start_epoch + 10):\n","        model.train()\n","        for inputs, labels in train_loader:\n","            optimizer.zero_grad()\n","            inputs = inputs.permute((0,3,1,2))\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels.float().unsqueeze(1))\n","            loss.backward()\n","            optimizer.step()\n","\n","        save_ckpt(model, optimizer, epoch + 1, params['num_neurons'], checkpoint_dir) # Save the checkpoint\n","\n","        model.eval()\n","        correct = 0\n","        total = 0\n","        with torch.no_grad():\n","            for inputs, labels in test_loader:\n","                inputs = inputs.permute((0,3,1,2))\n","                outputs = model(inputs)\n","                predicted = (outputs >= 0.5).squeeze().long()\n","                total += labels.size(0)\n","                correct += (predicted == labels).sum().item()\n","\n","        accuracy = correct / total\n","        print(\"Epoch: {}, Accuracy: {}\".format(epoch + 1, accuracy))\n","        if accuracy > best_accuracy:\n","            best_accuracy = accuracy\n","            best_params = params\n","\n","print(\"Best Accuracy:\", best_accuracy)\n","print(\"Best Parameters:\", best_params)\n"]},{"cell_type":"code","execution_count":null,"id":"c5d4d394","metadata":{"id":"c5d4d394","outputId":"9f317121-f7ff-4338-95b8-2b48a6d5fc78"},"outputs":[{"name":"stdout","output_type":"stream","text":["The prediction for image 12821_idx5_x1001_y1551_class1.png is: 0\n","The prediction for image 12821_idx5_x1001_y1601_class1.png is: 0\n","The prediction for image 12821_idx5_x1001_y1651_class1.png is: 0\n","The prediction for image 12821_idx5_x1001_y1701_class1.png is: 0\n","The prediction for image 12821_idx5_x1001_y1751_class1.png is: 0\n","The prediction for image 12821_idx5_x1051_y1101_class1.png is: 0\n","The prediction for image 12821_idx5_x1051_y1151_class1.png is: 0\n","The prediction for image 12821_idx5_x1051_y1501_class1.png is: 0\n","The prediction for image 12821_idx5_x1051_y1551_class1.png is: 0\n","The prediction for image 12821_idx5_x1051_y1601_class1.png is: 0\n","The prediction for image 12821_idx5_x1051_y1651_class1.png is: 0\n","The prediction for image 12821_idx5_x1051_y1701_class1.png is: 0\n","The prediction for image 12821_idx5_x1051_y1751_class1.png is: 0\n","The prediction for image 12821_idx5_x1101_y1051_class1.png is: 0\n","The prediction for image 12821_idx5_x1101_y1101_class1.png is: 0\n","The prediction for image 12821_idx5_x1101_y1151_class1.png is: 0\n","The prediction for image 12821_idx5_x1101_y1201_class1.png is: 0\n","The prediction for image 12821_idx5_x1101_y1501_class1.png is: 0\n","The prediction for image 12821_idx5_x1101_y1551_class1.png is: 0\n","The prediction for image 12821_idx5_x1101_y1601_class1.png is: 0\n","The prediction for image 12821_idx5_x1101_y1651_class1.png is: 0\n","The prediction for image 12821_idx5_x1101_y1701_class1.png is: 0\n","The prediction for image 12821_idx5_x1101_y1751_class1.png is: 0\n","The prediction for image 12821_idx5_x1101_y1801_class1.png is: 0\n","The prediction for image 12821_idx5_x1151_y1001_class1.png is: 0\n","The prediction for image 12821_idx5_x1151_y1051_class1.png is: 0\n","The prediction for image 12821_idx5_x1151_y1101_class1.png is: 0\n","The prediction for image 12821_idx5_x1151_y1151_class1.png is: 0\n","The prediction for image 12821_idx5_x1151_y1551_class1.png is: 0\n","The prediction for image 12821_idx5_x1151_y1601_class1.png is: 0\n","The prediction for image 12821_idx5_x1151_y1701_class1.png is: 0\n","The prediction for image 12821_idx5_x1151_y1751_class1.png is: 0\n","The prediction for image 12821_idx5_x1151_y1801_class1.png is: 0\n","The prediction for image 12821_idx5_x1201_y1001_class1.png is: 0\n","The prediction for image 12821_idx5_x1201_y1051_class1.png is: 0\n","The prediction for image 12821_idx5_x1201_y1101_class1.png is: 0\n","The prediction for image 12821_idx5_x1201_y1151_class1.png is: 0\n","The prediction for image 12821_idx5_x1201_y1551_class1.png is: 0\n","The prediction for image 12821_idx5_x1201_y1601_class1.png is: 0\n","The prediction for image 12821_idx5_x1201_y1701_class1.png is: 0\n","The prediction for image 12821_idx5_x1201_y1751_class1.png is: 0\n","The prediction for image 12821_idx5_x1201_y1801_class1.png is: 0\n","The prediction for image 12821_idx5_x1251_y1051_class1.png is: 0\n","The prediction for image 12821_idx5_x1251_y1101_class1.png is: 0\n","The prediction for image 12821_idx5_x1251_y1651_class1.png is: 0\n","The prediction for image 12821_idx5_x1251_y1701_class1.png is: 0\n","The prediction for image 12821_idx5_x1251_y1751_class1.png is: 0\n","The prediction for image 12821_idx5_x1251_y1801_class1.png is: 0\n","The prediction for image 12821_idx5_x1251_y1851_class1.png is: 0\n","The prediction for image 12821_idx5_x1301_y1001_class1.png is: 0\n","The prediction for image 12821_idx5_x1301_y1051_class1.png is: 0\n","The prediction for image 12821_idx5_x1301_y1101_class1.png is: 0\n","The prediction for image 12821_idx5_x1301_y1601_class1.png is: 0\n","The prediction for image 12821_idx5_x1301_y1651_class1.png is: 0\n","The prediction for image 12821_idx5_x1301_y1701_class1.png is: 0\n","The prediction for image 12821_idx5_x1301_y1751_class1.png is: 0\n","The prediction for image 12821_idx5_x1301_y1801_class1.png is: 0\n","The prediction for image 12821_idx5_x1301_y1851_class1.png is: 0\n","The prediction for image 12821_idx5_x1301_y1901_class1.png is: 0\n","The prediction for image 12821_idx5_x1301_y1951_class1.png is: 0\n","The prediction for image 12821_idx5_x1301_y2001_class1.png is: 0\n","The prediction for image 12821_idx5_x1351_y1001_class1.png is: 0\n","The prediction for image 12821_idx5_x1351_y1051_class1.png is: 0\n","The prediction for image 12821_idx5_x1351_y1101_class1.png is: 0\n","The prediction for image 12821_idx5_x1351_y1601_class1.png is: 0\n","The prediction for image 12821_idx5_x1351_y1651_class1.png is: 0\n","The prediction for image 12821_idx5_x1351_y1701_class1.png is: 0\n","The prediction for image 12821_idx5_x1351_y1751_class1.png is: 0\n","The prediction for image 12821_idx5_x1351_y1801_class1.png is: 0\n","The prediction for image 12821_idx5_x1351_y1851_class1.png is: 0\n","The prediction for image 12821_idx5_x1351_y1901_class1.png is: 0\n","The prediction for image 12821_idx5_x1351_y1951_class1.png is: 0\n","The prediction for image 12821_idx5_x1351_y2001_class1.png is: 0\n","The prediction for image 12821_idx5_x1351_y951_class1.png is: 0\n","The prediction for image 12821_idx5_x1401_y1001_class1.png is: 0\n","The prediction for image 12821_idx5_x1401_y1051_class1.png is: 0\n","The prediction for image 12821_idx5_x1401_y1101_class1.png is: 0\n","The prediction for image 12821_idx5_x1401_y1151_class1.png is: 0\n","The prediction for image 12821_idx5_x1401_y1601_class1.png is: 0\n","The prediction for image 12821_idx5_x1401_y1651_class1.png is: 0\n","The prediction for image 12821_idx5_x1401_y1701_class1.png is: 0\n","The prediction for image 12821_idx5_x1401_y1751_class1.png is: 0\n","The prediction for image 12821_idx5_x1401_y1801_class1.png is: 0\n","The prediction for image 12821_idx5_x1401_y1851_class1.png is: 0\n","The prediction for image 12821_idx5_x1401_y1901_class1.png is: 0\n","The prediction for image 12821_idx5_x1401_y1951_class1.png is: 0\n","The prediction for image 12821_idx5_x1401_y951_class1.png is: 0\n","The prediction for image 12821_idx5_x1451_y1001_class1.png is: 0\n","The prediction for image 12821_idx5_x1451_y1051_class1.png is: 0\n","The prediction for image 12821_idx5_x1451_y1101_class1.png is: 0\n","The prediction for image 12821_idx5_x1451_y1151_class1.png is: 0\n","The prediction for image 12821_idx5_x1451_y1601_class1.png is: 0\n","The prediction for image 12821_idx5_x1451_y1651_class1.png is: 0\n","The prediction for image 12821_idx5_x1451_y1701_class1.png is: 0\n","The prediction for image 12821_idx5_x1451_y1751_class1.png is: 0\n","The prediction for image 12821_idx5_x1451_y1801_class1.png is: 0\n","The prediction for image 12821_idx5_x1451_y1851_class1.png is: 0\n","The prediction for image 12821_idx5_x1451_y951_class1.png is: 0\n","The prediction for image 12821_idx5_x1501_y1001_class1.png is: 0\n","The prediction for image 12821_idx5_x1501_y1051_class1.png is: 0\n","The prediction for image 12821_idx5_x1501_y1101_class1.png is: 0\n","The prediction for image 12821_idx5_x1501_y1151_class1.png is: 0\n","The prediction for image 12821_idx5_x1501_y1601_class1.png is: 0\n","The prediction for image 12821_idx5_x1501_y1651_class1.png is: 0\n","The prediction for image 12821_idx5_x1501_y1701_class1.png is: 0\n","The prediction for image 12821_idx5_x1501_y1751_class1.png is: 0\n","The prediction for image 12821_idx5_x1501_y1801_class1.png is: 0\n","The prediction for image 12821_idx5_x1501_y1851_class1.png is: 0\n","The prediction for image 12821_idx5_x1501_y951_class1.png is: 0\n","The prediction for image 12821_idx5_x1551_y1001_class1.png is: 0\n","The prediction for image 12821_idx5_x1551_y1051_class1.png is: 0\n","The prediction for image 12821_idx5_x1551_y1101_class1.png is: 0\n","The prediction for image 12821_idx5_x1551_y1151_class1.png is: 0\n","The prediction for image 12821_idx5_x1551_y1501_class1.png is: 0\n","The prediction for image 12821_idx5_x1551_y1551_class1.png is: 0\n","The prediction for image 12821_idx5_x1551_y1651_class1.png is: 0\n","The prediction for image 12821_idx5_x1551_y1701_class1.png is: 0\n","The prediction for image 12821_idx5_x1551_y1751_class1.png is: 0\n","The prediction for image 12821_idx5_x1551_y1801_class1.png is: 0\n","The prediction for image 12821_idx5_x1551_y851_class1.png is: 0\n","The prediction for image 12821_idx5_x1551_y901_class1.png is: 0\n","The prediction for image 12821_idx5_x1551_y951_class1.png is: 0\n","The prediction for image 12821_idx5_x1601_y1001_class1.png is: 0\n","The prediction for image 12821_idx5_x1601_y1051_class1.png is: 0\n","The prediction for image 12821_idx5_x1601_y1101_class1.png is: 0\n","The prediction for image 12821_idx5_x1601_y1151_class1.png is: 0\n","The prediction for image 12821_idx5_x1601_y1201_class1.png is: 0\n","The prediction for image 12821_idx5_x1601_y1351_class1.png is: 0\n","The prediction for image 12821_idx5_x1601_y1401_class1.png is: 0\n","The prediction for image 12821_idx5_x1601_y1451_class1.png is: 0\n","The prediction for image 12821_idx5_x1601_y1501_class1.png is: 0\n","The prediction for image 12821_idx5_x1601_y1551_class1.png is: 0\n","The prediction for image 12821_idx5_x1601_y1601_class1.png is: 0\n","The prediction for image 12821_idx5_x1601_y1701_class1.png is: 0\n","The prediction for image 12821_idx5_x1601_y1751_class1.png is: 0\n","The prediction for image 12821_idx5_x1601_y1801_class1.png is: 0\n","The prediction for image 12821_idx5_x1601_y851_class1.png is: 0\n","The prediction for image 12821_idx5_x1601_y901_class1.png is: 0\n","The prediction for image 12821_idx5_x1601_y951_class1.png is: 0\n","The prediction for image 12821_idx5_x1651_y1001_class1.png is: 0\n","The prediction for image 12821_idx5_x1651_y1051_class1.png is: 0\n","The prediction for image 12821_idx5_x1651_y1101_class1.png is: 0\n","The prediction for image 12821_idx5_x1651_y1151_class1.png is: 0\n","The prediction for image 12821_idx5_x1651_y1201_class1.png is: 0\n","The prediction for image 12821_idx5_x1651_y1251_class1.png is: 0\n","The prediction for image 12821_idx5_x1651_y1301_class1.png is: 0\n","The prediction for image 12821_idx5_x1651_y1351_class1.png is: 0\n","The prediction for image 12821_idx5_x1651_y1401_class1.png is: 0\n","The prediction for image 12821_idx5_x1651_y1451_class1.png is: 0\n","The prediction for image 12821_idx5_x1651_y1501_class1.png is: 0\n","The prediction for image 12821_idx5_x1651_y1551_class1.png is: 0\n","The prediction for image 12821_idx5_x1651_y1601_class1.png is: 0\n","The prediction for image 12821_idx5_x1651_y1651_class1.png is: 0\n","The prediction for image 12821_idx5_x1651_y1701_class1.png is: 0\n","The prediction for image 12821_idx5_x1651_y1751_class1.png is: 0\n","The prediction for image 12821_idx5_x1651_y851_class1.png is: 0\n","The prediction for image 12821_idx5_x1651_y901_class1.png is: 0\n","The prediction for image 12821_idx5_x1651_y951_class1.png is: 0\n","The prediction for image 12821_idx5_x1701_y1001_class1.png is: 0\n","The prediction for image 12821_idx5_x1701_y1051_class1.png is: 0\n","The prediction for image 12821_idx5_x1701_y1101_class1.png is: 0\n","The prediction for image 12821_idx5_x1701_y1151_class1.png is: 0\n","The prediction for image 12821_idx5_x1701_y1201_class1.png is: 0\n","The prediction for image 12821_idx5_x1701_y1251_class1.png is: 0\n","The prediction for image 12821_idx5_x1701_y1301_class1.png is: 0\n","The prediction for image 12821_idx5_x1701_y1351_class1.png is: 0\n","The prediction for image 12821_idx5_x1701_y1401_class1.png is: 0\n","The prediction for image 12821_idx5_x1701_y1451_class1.png is: 0\n","The prediction for image 12821_idx5_x1701_y1501_class1.png is: 0\n","The prediction for image 12821_idx5_x1701_y1551_class1.png is: 0\n","The prediction for image 12821_idx5_x1701_y1601_class1.png is: 0\n","The prediction for image 12821_idx5_x1701_y1651_class1.png is: 0\n","The prediction for image 12821_idx5_x1701_y1701_class1.png is: 0\n","The prediction for image 12821_idx5_x1701_y1751_class1.png is: 0\n","The prediction for image 12821_idx5_x1701_y851_class1.png is: 0\n","The prediction for image 12821_idx5_x1701_y901_class1.png is: 0\n","The prediction for image 12821_idx5_x1701_y951_class1.png is: 0\n","The prediction for image 12821_idx5_x1751_y1001_class1.png is: 0\n","The prediction for image 12821_idx5_x1751_y1051_class1.png is: 0\n","The prediction for image 12821_idx5_x1751_y1101_class1.png is: 0\n","The prediction for image 12821_idx5_x1751_y1151_class1.png is: 0\n","The prediction for image 12821_idx5_x1751_y1201_class1.png is: 0\n","The prediction for image 12821_idx5_x1751_y1251_class1.png is: 0\n","The prediction for image 12821_idx5_x1751_y1301_class1.png is: 0\n","The prediction for image 12821_idx5_x1751_y1351_class1.png is: 0\n","The prediction for image 12821_idx5_x1751_y1401_class1.png is: 0\n"]},{"name":"stdout","output_type":"stream","text":["The prediction for image 12821_idx5_x1751_y1451_class1.png is: 0\n","The prediction for image 12821_idx5_x1751_y1501_class1.png is: 0\n","The prediction for image 12821_idx5_x1751_y1551_class1.png is: 0\n","The prediction for image 12821_idx5_x1751_y1601_class1.png is: 0\n","The prediction for image 12821_idx5_x1751_y1651_class1.png is: 0\n","The prediction for image 12821_idx5_x1751_y1701_class1.png is: 0\n","The prediction for image 12821_idx5_x1751_y1751_class1.png is: 0\n","The prediction for image 12821_idx5_x1751_y851_class1.png is: 0\n","The prediction for image 12821_idx5_x1751_y901_class1.png is: 0\n","The prediction for image 12821_idx5_x1751_y951_class1.png is: 0\n","The prediction for image 12821_idx5_x1801_y1001_class1.png is: 0\n","The prediction for image 12821_idx5_x1801_y1051_class1.png is: 0\n","The prediction for image 12821_idx5_x1801_y1101_class1.png is: 0\n","The prediction for image 12821_idx5_x1801_y1151_class1.png is: 0\n","The prediction for image 12821_idx5_x1801_y1201_class1.png is: 0\n","The prediction for image 12821_idx5_x1801_y1251_class1.png is: 0\n","The prediction for image 12821_idx5_x1801_y1301_class1.png is: 0\n","The prediction for image 12821_idx5_x1801_y1351_class1.png is: 0\n","The prediction for image 12821_idx5_x1801_y1401_class1.png is: 0\n","The prediction for image 12821_idx5_x1801_y1451_class1.png is: 0\n","The prediction for image 12821_idx5_x1801_y1501_class1.png is: 0\n","The prediction for image 12821_idx5_x1801_y1551_class1.png is: 0\n","The prediction for image 12821_idx5_x1801_y1601_class1.png is: 0\n","The prediction for image 12821_idx5_x1801_y1651_class1.png is: 0\n","The prediction for image 12821_idx5_x1801_y1701_class1.png is: 0\n","The prediction for image 12821_idx5_x1801_y801_class1.png is: 0\n","The prediction for image 12821_idx5_x1801_y851_class1.png is: 0\n","The prediction for image 12821_idx5_x1801_y901_class1.png is: 0\n","The prediction for image 12821_idx5_x1801_y951_class1.png is: 0\n","The prediction for image 12821_idx5_x1851_y1001_class1.png is: 0\n","The prediction for image 12821_idx5_x1851_y1051_class1.png is: 0\n","The prediction for image 12821_idx5_x1851_y1101_class1.png is: 0\n","The prediction for image 12821_idx5_x1851_y1151_class1.png is: 0\n","The prediction for image 12821_idx5_x1851_y1201_class1.png is: 0\n","The prediction for image 12821_idx5_x1851_y1251_class1.png is: 0\n","The prediction for image 12821_idx5_x1851_y1301_class1.png is: 0\n","The prediction for image 12821_idx5_x1851_y1351_class1.png is: 0\n","The prediction for image 12821_idx5_x1851_y1401_class1.png is: 0\n","The prediction for image 12821_idx5_x1851_y1451_class1.png is: 0\n","The prediction for image 12821_idx5_x1851_y1501_class1.png is: 0\n","The prediction for image 12821_idx5_x1851_y1551_class1.png is: 0\n","The prediction for image 12821_idx5_x1851_y1601_class1.png is: 0\n","The prediction for image 12821_idx5_x1851_y1651_class1.png is: 0\n","The prediction for image 12821_idx5_x1851_y1701_class1.png is: 0\n","The prediction for image 12821_idx5_x1851_y801_class1.png is: 0\n","The prediction for image 12821_idx5_x1851_y851_class1.png is: 0\n","The prediction for image 12821_idx5_x1851_y901_class1.png is: 0\n","The prediction for image 12821_idx5_x1851_y951_class1.png is: 0\n","The prediction for image 12821_idx5_x1901_y1001_class1.png is: 0\n","The prediction for image 12821_idx5_x1901_y1051_class1.png is: 0\n","The prediction for image 12821_idx5_x1901_y1101_class1.png is: 0\n","The prediction for image 12821_idx5_x1901_y1151_class1.png is: 0\n","The prediction for image 12821_idx5_x1901_y1201_class1.png is: 0\n","The prediction for image 12821_idx5_x1901_y1251_class1.png is: 0\n","The prediction for image 12821_idx5_x1901_y1301_class1.png is: 0\n","The prediction for image 12821_idx5_x1901_y1351_class1.png is: 0\n","The prediction for image 12821_idx5_x1901_y1401_class1.png is: 0\n","The prediction for image 12821_idx5_x1901_y1451_class1.png is: 0\n","The prediction for image 12821_idx5_x1901_y1501_class1.png is: 0\n","The prediction for image 12821_idx5_x1901_y1551_class1.png is: 0\n","The prediction for image 12821_idx5_x1901_y1601_class1.png is: 0\n","The prediction for image 12821_idx5_x1901_y1651_class1.png is: 0\n","The prediction for image 12821_idx5_x1901_y751_class1.png is: 0\n","The prediction for image 12821_idx5_x1901_y801_class1.png is: 0\n","The prediction for image 12821_idx5_x1901_y851_class1.png is: 0\n","The prediction for image 12821_idx5_x1901_y901_class1.png is: 0\n","The prediction for image 12821_idx5_x1901_y951_class1.png is: 0\n","The prediction for image 12821_idx5_x1951_y1001_class1.png is: 0\n","The prediction for image 12821_idx5_x1951_y1051_class1.png is: 0\n","The prediction for image 12821_idx5_x1951_y1101_class1.png is: 0\n","The prediction for image 12821_idx5_x1951_y1151_class1.png is: 0\n","The prediction for image 12821_idx5_x1951_y1201_class1.png is: 0\n","The prediction for image 12821_idx5_x1951_y1251_class1.png is: 0\n","The prediction for image 12821_idx5_x1951_y1301_class1.png is: 0\n","The prediction for image 12821_idx5_x1951_y1351_class1.png is: 0\n","The prediction for image 12821_idx5_x1951_y1401_class1.png is: 0\n","The prediction for image 12821_idx5_x1951_y1451_class1.png is: 0\n","The prediction for image 12821_idx5_x1951_y1501_class1.png is: 0\n","The prediction for image 12821_idx5_x1951_y1551_class1.png is: 0\n","The prediction for image 12821_idx5_x1951_y1601_class1.png is: 0\n","The prediction for image 12821_idx5_x1951_y1651_class1.png is: 0\n","The prediction for image 12821_idx5_x1951_y751_class1.png is: 0\n","The prediction for image 12821_idx5_x1951_y801_class1.png is: 0\n","The prediction for image 12821_idx5_x1951_y851_class1.png is: 0\n","The prediction for image 12821_idx5_x1951_y901_class1.png is: 0\n","The prediction for image 12821_idx5_x1951_y951_class1.png is: 0\n","The prediction for image 12821_idx5_x2001_y1001_class1.png is: 0\n","The prediction for image 12821_idx5_x2001_y1051_class1.png is: 0\n","The prediction for image 12821_idx5_x2001_y1101_class1.png is: 0\n","The prediction for image 12821_idx5_x2001_y1151_class1.png is: 0\n","The prediction for image 12821_idx5_x2001_y1201_class1.png is: 0\n","The prediction for image 12821_idx5_x2001_y1251_class1.png is: 0\n","The prediction for image 12821_idx5_x2001_y1301_class1.png is: 0\n","The prediction for image 12821_idx5_x2001_y1351_class1.png is: 0\n","The prediction for image 12821_idx5_x2001_y1401_class1.png is: 0\n","The prediction for image 12821_idx5_x2001_y1451_class1.png is: 0\n","The prediction for image 12821_idx5_x2001_y1501_class1.png is: 0\n","The prediction for image 12821_idx5_x2001_y1551_class1.png is: 0\n","The prediction for image 12821_idx5_x2001_y1601_class1.png is: 0\n","The prediction for image 12821_idx5_x2001_y951_class1.png is: 0\n","The prediction for image 12821_idx5_x2051_y1051_class1.png is: 0\n","The prediction for image 12821_idx5_x2051_y1101_class1.png is: 0\n","The prediction for image 12821_idx5_x2051_y1151_class1.png is: 0\n","The prediction for image 12821_idx5_x2051_y1201_class1.png is: 0\n","The prediction for image 12821_idx5_x2051_y1251_class1.png is: 0\n","The prediction for image 12821_idx5_x2051_y1301_class1.png is: 0\n","The prediction for image 12821_idx5_x2051_y1351_class1.png is: 0\n","The prediction for image 12821_idx5_x2051_y1401_class1.png is: 0\n","The prediction for image 12821_idx5_x2051_y1451_class1.png is: 0\n","The prediction for image 12821_idx5_x2051_y1501_class1.png is: 0\n","The prediction for image 12821_idx5_x2051_y1551_class1.png is: 0\n","The prediction for image 12821_idx5_x2101_y1151_class1.png is: 0\n","The prediction for image 12821_idx5_x2101_y1201_class1.png is: 0\n","The prediction for image 12821_idx5_x2101_y1251_class1.png is: 0\n","The prediction for image 12821_idx5_x2101_y1301_class1.png is: 0\n","The prediction for image 12821_idx5_x2101_y1351_class1.png is: 0\n","The prediction for image 12821_idx5_x2101_y1401_class1.png is: 0\n","The prediction for image 12821_idx5_x2151_y1201_class1.png is: 0\n","The prediction for image 12821_idx5_x2151_y1251_class1.png is: 0\n","The prediction for image 12821_idx5_x2151_y1301_class1.png is: 0\n","The prediction for image 12821_idx5_x2151_y1351_class1.png is: 0\n","The prediction for image 12821_idx5_x2151_y1401_class1.png is: 0\n","The prediction for image 12821_idx5_x2201_y1151_class1.png is: 0\n","The prediction for image 12821_idx5_x2201_y1201_class1.png is: 0\n","The prediction for image 12821_idx5_x2201_y1251_class1.png is: 0\n","The prediction for image 12821_idx5_x2201_y1301_class1.png is: 0\n","The prediction for image 12821_idx5_x2201_y1351_class1.png is: 0\n","The prediction for image 12821_idx5_x2251_y1151_class1.png is: 0\n","The prediction for image 12821_idx5_x2251_y1201_class1.png is: 0\n","The prediction for image 12821_idx5_x2251_y1251_class1.png is: 0\n","The prediction for image 12821_idx5_x2251_y1301_class1.png is: 0\n","The prediction for image 12821_idx5_x951_y1701_class1.png is: 0\n","The prediction for image 12821_idx5_x951_y1751_class1.png is: 0\n"]}],"source":["# PREDICCIONES\n","\n","import os\n","from PIL import Image\n","import torchvision.transforms as transforms\n","\n","# Define la transformación que necesitas aplicar en las imágenes\n","# Para hacerla compatible con tu modelo\n","transform = transforms.Compose([\n","    transforms.Resize((50,50)),      # Redimensionar a 50x50\n","    transforms.ToTensor(),           # Convertir a tensor\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # Normalizar como se hizo durante el entrenamiento\n","])\n","\n","# Define la ruta de tu directorio\n","directory = \"D:\\\\Master\\\\TFM\\\\IDC_regular_ps50_idx5\\\\12821\\\\1\"\n","\n","# Obtiene una lista de todos los archivos en el directorio\n","image_files = os.listdir(directory)\n","\n","# Itera sobre cada archivo de imagen\n","for image_file in image_files:\n","    # Abre la imagen usando PIL\n","    image_pred = Image.open(os.path.join(directory, image_file))\n","\n","    # Aplica las transformaciones a la imagen\n","    image_p_tensor = transform(image_pred)\n","\n","    # Añade una dimensión extra en la posición 0\n","    image_p_tensor = image_p_tensor.unsqueeze(0)\n","\n","    # Asegúrate de que el modelo está en modo de evaluación\n","    model.eval()\n","\n","    # Realiza la predicción\n","    with torch.no_grad():\n","        output_p = model(image_p_tensor)\n","        prediction = (output_p >= 0.5).squeeze().long()\n","\n","    # Imprime la predicción\n","    print(f\"The prediction for image {image_file} is: {prediction.item()}\")\n"]},{"cell_type":"code","execution_count":null,"id":"b89c6e8e","metadata":{"id":"b89c6e8e","outputId":"5df1587f-736f-4e07-dc4c-f7a8079f4a93"},"outputs":[{"ename":"PermissionError","evalue":"[Errno 13] Permission denied: '/content'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)","Cell \u001b[0;32mIn [23], line 68\u001b[0m\n\u001b[1;32m     65\u001b[0m checkpoint_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/checkpoints/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Create checkpoint directory if it doesn't exist\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_ckpt\u001b[39m(model, optimizer, epoch, num_neurons, checkpoint_dir):\n\u001b[1;32m     71\u001b[0m     save_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(checkpoint_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpoint_\u001b[39m\u001b[38;5;132;01m{:04d}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch, num_neurons))\n","File \u001b[0;32m/usr/lib/python3.8/os.py:213\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head \u001b[38;5;129;01mand\u001b[39;00m tail \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists(head):\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 213\u001b[0m         \u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexist_ok\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileExistsError\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;66;03m# Defeats race condition when another thread created the path\u001b[39;00m\n\u001b[1;32m    216\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n","File \u001b[0;32m/usr/lib/python3.8/os.py:223\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 223\u001b[0m     \u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exist_ok \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39misdir(name):\n","\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/content'"]}],"source":["#Pruebas para arreglar lo del otro codigo\n","# Import necessary libraries\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import ParameterGrid\n","\n","# Convert lists to tensors\n","imagenes = torch.stack([torch.Tensor(i) for i in imagenes])\n","etiquetas = torch.tensor(listado_arrays_etiquetas)\n","\n","# Split data into training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(imagenes, etiquetas, test_size=0.2, random_state=42)\n","\n","# Define custom dataset\n","class CustomDataset(Dataset):\n","    def __init__(self, X, y):\n","        self.X = X\n","        self.y = y\n","\n","    def __len__(self):\n","        return len(self.X)\n","\n","    def __getitem__(self, idx):\n","        return self.X[idx], self.y[idx]\n","\n","# Create train and test datasets\n","train_dataset = CustomDataset(X_train, y_train)\n","test_dataset = CustomDataset(X_test, y_test)\n","\n","# Define the model architecture\n","class Model(nn.Module):\n","    def __init__(self, num_neurons):\n","        super(Model, self).__init__()\n","        self.conv1 = nn.Conv2d(3, num_neurons, 3)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.fc = nn.Linear(num_neurons*127*127, 1)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = x.view(-1, self.num_flat_features(x))\n","        x = self.sigmoid(self.fc(x))\n","        return x\n","\n","    def num_flat_features(self, x):\n","        size = x.size()[1:]  # all dimensions except the batch dimension\n","        num_features = 1\n","        for s in size:\n","            num_features *= s\n","        return num_features\n","\n","# Define the function to create the model\n","def crear_modelo(num_neurons):\n","    model = Model(num_neurons)\n","    criterion = nn.BCELoss()\n","    optimizer = optim.Adam(model.parameters())\n","    return model, criterion, optimizer\n","\n","# Define the checkpoint directory\n","checkpoint_dir = '/content/checkpoints/'\n","\n","# Create checkpoint directory if it doesn't exist\n","os.makedirs(checkpoint_dir, exist_ok=True)\n","\n","def save_ckpt(model, optimizer, epoch, num_neurons, checkpoint_dir):\n","    save_dir = os.path.join(checkpoint_dir, \"checkpoint_{:04d}_{}.pth\".format(epoch, num_neurons))\n","\n","    cp = {\n","        'model': model.state_dict(),\n","        'optimizer': optimizer.state_dict(),\n","        'epoch': epoch,\n","    }\n","\n","    torch.save(cp, save_dir)\n","    print(\"Saved checkpoint into {}\".format(save_dir))\n","\n","\n","def load_ckpt(checkpoint_dir, num_neurons):\n","    last_epoch = 0\n","    checkpoint_file = ''\n","\n","    for file in os.listdir(checkpoint_dir):\n","        if file.endswith('{}.pth'.format(num_neurons)):\n","            epoch_number = int(file.split('_')[1])\n","            if epoch_number > last_epoch:\n","                last_epoch = epoch_number\n","                checkpoint_file = file\n","\n","    if last_epoch == 0:\n","        return None, 0\n","    else:\n","        print(\"Loaded checkpoint\", os.path.join(checkpoint_dir, checkpoint_file))\n","        checkpoint = torch.load(os.path.join(checkpoint_dir, checkpoint_file))\n","        return checkpoint, checkpoint['epoch']\n","\n","# Define the grid of parameters\n","param_grid = {\n","    'num_neurons': [10, 20, 30, 40, 50],\n","}\n","\n","# Perform grid search\n","best_accuracy = 0.0\n","best_params = None\n","\n","for params in ParameterGrid(param_grid):\n","    print(\"Using {} neurons\".format(params['num_neurons']))\n","    model, criterion, optimizer = crear_modelo(params['num_neurons'])\n","    checkpoint, start_epoch = load_ckpt(checkpoint_dir, params['num_neurons'])\n","    if checkpoint is not None:\n","        model.load_state_dict(checkpoint['model'])\n","        optimizer.load_state_dict(checkpoint['optimizer'])\n","\n","    train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n","    test_loader = DataLoader(test_dataset, batch_size=10, shuffle=False)\n","\n","    for epoch in range(start_epoch, start_epoch + 10):\n","        model.train()\n","        for inputs, labels in train_loader:\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels.float().unsqueeze(1))\n","            loss.backward()\n","            optimizer.step()\n","\n","        save_ckpt(model, optimizer, epoch + 1, params['num_neurons'], checkpoint_dir) # Save the checkpoint\n","\n","        model.eval()\n","        correct = 0\n","        total = 0\n","        with torch.no_grad():\n","            for inputs, labels in test_loader:\n","                outputs = model(inputs)\n","                predicted = (outputs >= 0.5).squeeze().long()\n","                total += labels.size(0)\n","                correct += (predicted == labels).sum().item()\n","\n","        accuracy = correct / total\n","        print(\"Epoch: {}, Accuracy: {}\".format(epoch + 1, accuracy))\n","        if accuracy > best_accuracy:\n","            best_accuracy = accuracy\n","            best_params = params\n","\n","print(\"Best Accuracy:\", best_accuracy)\n","print(\"Best Parameters:\", best_params)\n"]},{"cell_type":"code","execution_count":null,"id":"620505a8","metadata":{"id":"620505a8","outputId":"ffc1161c-2fec-40c3-c38a-fe42d728567f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using 10 neurons\n","CREAR MODELO 10\n","Loaded checkpoint D:/Master/TFM/Checkpoints\\checkpoint_0010_10.pth\n","torch.Size([10, 80, 1, 1])\n","torch.Size([10, 80, 1, 1])\n","torch.Size([10, 80, 1, 1])\n","torch.Size([3, 80, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0011_10.pth\n","torch.Size([9, 80, 1, 1])\n","Epoch: 11, Accuracy: 0.8888888888888888\n","torch.Size([10, 80, 1, 1])\n","torch.Size([10, 80, 1, 1])\n","torch.Size([10, 80, 1, 1])\n","torch.Size([3, 80, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0012_10.pth\n","torch.Size([9, 80, 1, 1])\n","Epoch: 12, Accuracy: 0.8888888888888888\n","torch.Size([10, 80, 1, 1])\n","torch.Size([10, 80, 1, 1])\n","torch.Size([10, 80, 1, 1])\n","torch.Size([3, 80, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0013_10.pth\n","torch.Size([9, 80, 1, 1])\n","Epoch: 13, Accuracy: 0.4444444444444444\n","torch.Size([10, 80, 1, 1])\n","torch.Size([10, 80, 1, 1])\n","torch.Size([10, 80, 1, 1])\n","torch.Size([3, 80, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0014_10.pth\n","torch.Size([9, 80, 1, 1])\n","Epoch: 14, Accuracy: 0.7777777777777778\n","torch.Size([10, 80, 1, 1])\n","torch.Size([10, 80, 1, 1])\n","torch.Size([10, 80, 1, 1])\n","torch.Size([3, 80, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0015_10.pth\n","torch.Size([9, 80, 1, 1])\n","Epoch: 15, Accuracy: 0.8888888888888888\n","torch.Size([10, 80, 1, 1])\n","torch.Size([10, 80, 1, 1])\n","torch.Size([10, 80, 1, 1])\n","torch.Size([3, 80, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0016_10.pth\n","torch.Size([9, 80, 1, 1])\n","Epoch: 16, Accuracy: 0.7777777777777778\n","torch.Size([10, 80, 1, 1])\n","torch.Size([10, 80, 1, 1])\n","torch.Size([10, 80, 1, 1])\n","torch.Size([3, 80, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0017_10.pth\n","torch.Size([9, 80, 1, 1])\n","Epoch: 17, Accuracy: 0.8888888888888888\n","torch.Size([10, 80, 1, 1])\n","torch.Size([10, 80, 1, 1])\n","torch.Size([10, 80, 1, 1])\n","torch.Size([3, 80, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0018_10.pth\n","torch.Size([9, 80, 1, 1])\n","Epoch: 18, Accuracy: 0.8888888888888888\n","torch.Size([10, 80, 1, 1])\n","torch.Size([10, 80, 1, 1])\n","torch.Size([10, 80, 1, 1])\n","torch.Size([3, 80, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0019_10.pth\n","torch.Size([9, 80, 1, 1])\n","Epoch: 19, Accuracy: 0.8888888888888888\n","torch.Size([10, 80, 1, 1])\n","torch.Size([10, 80, 1, 1])\n","torch.Size([10, 80, 1, 1])\n","torch.Size([3, 80, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0020_10.pth\n","torch.Size([9, 80, 1, 1])\n","Epoch: 20, Accuracy: 0.8888888888888888\n","Using 20 neurons\n","CREAR MODELO 20\n","torch.Size([10, 160, 1, 1])\n","torch.Size([10, 160, 1, 1])\n","torch.Size([10, 160, 1, 1])\n","torch.Size([3, 160, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0001_20.pth\n","torch.Size([9, 160, 1, 1])\n","Epoch: 1, Accuracy: 0.4444444444444444\n","torch.Size([10, 160, 1, 1])\n","torch.Size([10, 160, 1, 1])\n","torch.Size([10, 160, 1, 1])\n","torch.Size([3, 160, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0002_20.pth\n","torch.Size([9, 160, 1, 1])\n","Epoch: 2, Accuracy: 0.6666666666666666\n","torch.Size([10, 160, 1, 1])\n","torch.Size([10, 160, 1, 1])\n","torch.Size([10, 160, 1, 1])\n","torch.Size([3, 160, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0003_20.pth\n","torch.Size([9, 160, 1, 1])\n","Epoch: 3, Accuracy: 0.4444444444444444\n","torch.Size([10, 160, 1, 1])\n","torch.Size([10, 160, 1, 1])\n","torch.Size([10, 160, 1, 1])\n","torch.Size([3, 160, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0004_20.pth\n","torch.Size([9, 160, 1, 1])\n","Epoch: 4, Accuracy: 0.4444444444444444\n","torch.Size([10, 160, 1, 1])\n","torch.Size([10, 160, 1, 1])\n","torch.Size([10, 160, 1, 1])\n","torch.Size([3, 160, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0005_20.pth\n","torch.Size([9, 160, 1, 1])\n","Epoch: 5, Accuracy: 0.4444444444444444\n","torch.Size([10, 160, 1, 1])\n","torch.Size([10, 160, 1, 1])\n","torch.Size([10, 160, 1, 1])\n","torch.Size([3, 160, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0006_20.pth\n","torch.Size([9, 160, 1, 1])\n","Epoch: 6, Accuracy: 0.6666666666666666\n","torch.Size([10, 160, 1, 1])\n","torch.Size([10, 160, 1, 1])\n","torch.Size([10, 160, 1, 1])\n","torch.Size([3, 160, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0007_20.pth\n","torch.Size([9, 160, 1, 1])\n","Epoch: 7, Accuracy: 0.6666666666666666\n","torch.Size([10, 160, 1, 1])\n","torch.Size([10, 160, 1, 1])\n","torch.Size([10, 160, 1, 1])\n","torch.Size([3, 160, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0008_20.pth\n","torch.Size([9, 160, 1, 1])\n","Epoch: 8, Accuracy: 0.6666666666666666\n","torch.Size([10, 160, 1, 1])\n","torch.Size([10, 160, 1, 1])\n","torch.Size([10, 160, 1, 1])\n","torch.Size([3, 160, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0009_20.pth\n","torch.Size([9, 160, 1, 1])\n","Epoch: 9, Accuracy: 0.6666666666666666\n","torch.Size([10, 160, 1, 1])\n","torch.Size([10, 160, 1, 1])\n","torch.Size([10, 160, 1, 1])\n","torch.Size([3, 160, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0010_20.pth\n","torch.Size([9, 160, 1, 1])\n","Epoch: 10, Accuracy: 0.5555555555555556\n","Using 30 neurons\n","CREAR MODELO 30\n","torch.Size([10, 240, 1, 1])\n","torch.Size([10, 240, 1, 1])\n","torch.Size([10, 240, 1, 1])\n","torch.Size([3, 240, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0001_30.pth\n","torch.Size([9, 240, 1, 1])\n","Epoch: 1, Accuracy: 0.4444444444444444\n","torch.Size([10, 240, 1, 1])\n","torch.Size([10, 240, 1, 1])\n","torch.Size([10, 240, 1, 1])\n","torch.Size([3, 240, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0002_30.pth\n","torch.Size([9, 240, 1, 1])\n","Epoch: 2, Accuracy: 0.4444444444444444\n","torch.Size([10, 240, 1, 1])\n","torch.Size([10, 240, 1, 1])\n","torch.Size([10, 240, 1, 1])\n","torch.Size([3, 240, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0003_30.pth\n","torch.Size([9, 240, 1, 1])\n","Epoch: 3, Accuracy: 0.4444444444444444\n","torch.Size([10, 240, 1, 1])\n","torch.Size([10, 240, 1, 1])\n","torch.Size([10, 240, 1, 1])\n","torch.Size([3, 240, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0004_30.pth\n","torch.Size([9, 240, 1, 1])\n","Epoch: 4, Accuracy: 0.5555555555555556\n","torch.Size([10, 240, 1, 1])\n","torch.Size([10, 240, 1, 1])\n","torch.Size([10, 240, 1, 1])\n","torch.Size([3, 240, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0005_30.pth\n","torch.Size([9, 240, 1, 1])\n","Epoch: 5, Accuracy: 0.4444444444444444\n","torch.Size([10, 240, 1, 1])\n","torch.Size([10, 240, 1, 1])\n","torch.Size([10, 240, 1, 1])\n","torch.Size([3, 240, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0006_30.pth\n","torch.Size([9, 240, 1, 1])\n","Epoch: 6, Accuracy: 0.4444444444444444\n","torch.Size([10, 240, 1, 1])\n","torch.Size([10, 240, 1, 1])\n","torch.Size([10, 240, 1, 1])\n","torch.Size([3, 240, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0007_30.pth\n","torch.Size([9, 240, 1, 1])\n","Epoch: 7, Accuracy: 0.5555555555555556\n","torch.Size([10, 240, 1, 1])\n","torch.Size([10, 240, 1, 1])\n","torch.Size([10, 240, 1, 1])\n","torch.Size([3, 240, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0008_30.pth\n","torch.Size([9, 240, 1, 1])\n","Epoch: 8, Accuracy: 0.6666666666666666\n","torch.Size([10, 240, 1, 1])\n","torch.Size([10, 240, 1, 1])\n","torch.Size([10, 240, 1, 1])\n","torch.Size([3, 240, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0009_30.pth\n","torch.Size([9, 240, 1, 1])\n","Epoch: 9, Accuracy: 0.6666666666666666\n","torch.Size([10, 240, 1, 1])\n","torch.Size([10, 240, 1, 1])\n","torch.Size([10, 240, 1, 1])\n","torch.Size([3, 240, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0010_30.pth\n","torch.Size([9, 240, 1, 1])\n","Epoch: 10, Accuracy: 0.7777777777777778\n","Using 40 neurons\n","CREAR MODELO 40\n","torch.Size([10, 320, 1, 1])\n","torch.Size([10, 320, 1, 1])\n","torch.Size([10, 320, 1, 1])\n","torch.Size([3, 320, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0001_40.pth\n","torch.Size([9, 320, 1, 1])\n","Epoch: 1, Accuracy: 0.4444444444444444\n","torch.Size([10, 320, 1, 1])\n","torch.Size([10, 320, 1, 1])\n","torch.Size([10, 320, 1, 1])\n","torch.Size([3, 320, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0002_40.pth\n","torch.Size([9, 320, 1, 1])\n","Epoch: 2, Accuracy: 0.4444444444444444\n","torch.Size([10, 320, 1, 1])\n","torch.Size([10, 320, 1, 1])\n","torch.Size([10, 320, 1, 1])\n","torch.Size([3, 320, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0003_40.pth\n","torch.Size([9, 320, 1, 1])\n","Epoch: 3, Accuracy: 0.4444444444444444\n","torch.Size([10, 320, 1, 1])\n","torch.Size([10, 320, 1, 1])\n"]},{"name":"stdout","output_type":"stream","text":["torch.Size([10, 320, 1, 1])\n","torch.Size([3, 320, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0004_40.pth\n","torch.Size([9, 320, 1, 1])\n","Epoch: 4, Accuracy: 0.5555555555555556\n","torch.Size([10, 320, 1, 1])\n","torch.Size([10, 320, 1, 1])\n","torch.Size([10, 320, 1, 1])\n","torch.Size([3, 320, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0005_40.pth\n","torch.Size([9, 320, 1, 1])\n","Epoch: 5, Accuracy: 0.5555555555555556\n","torch.Size([10, 320, 1, 1])\n","torch.Size([10, 320, 1, 1])\n","torch.Size([10, 320, 1, 1])\n","torch.Size([3, 320, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0006_40.pth\n","torch.Size([9, 320, 1, 1])\n","Epoch: 6, Accuracy: 0.7777777777777778\n","torch.Size([10, 320, 1, 1])\n","torch.Size([10, 320, 1, 1])\n","torch.Size([10, 320, 1, 1])\n","torch.Size([3, 320, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0007_40.pth\n","torch.Size([9, 320, 1, 1])\n","Epoch: 7, Accuracy: 0.7777777777777778\n","torch.Size([10, 320, 1, 1])\n","torch.Size([10, 320, 1, 1])\n","torch.Size([10, 320, 1, 1])\n","torch.Size([3, 320, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0008_40.pth\n","torch.Size([9, 320, 1, 1])\n","Epoch: 8, Accuracy: 0.5555555555555556\n","torch.Size([10, 320, 1, 1])\n","torch.Size([10, 320, 1, 1])\n","torch.Size([10, 320, 1, 1])\n","torch.Size([3, 320, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0009_40.pth\n","torch.Size([9, 320, 1, 1])\n","Epoch: 9, Accuracy: 0.6666666666666666\n","torch.Size([10, 320, 1, 1])\n","torch.Size([10, 320, 1, 1])\n","torch.Size([10, 320, 1, 1])\n","torch.Size([3, 320, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0010_40.pth\n","torch.Size([9, 320, 1, 1])\n","Epoch: 10, Accuracy: 0.5555555555555556\n","Using 50 neurons\n","CREAR MODELO 50\n","torch.Size([10, 400, 1, 1])\n","torch.Size([10, 400, 1, 1])\n","torch.Size([10, 400, 1, 1])\n","torch.Size([3, 400, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0001_50.pth\n","torch.Size([9, 400, 1, 1])\n","Epoch: 1, Accuracy: 0.4444444444444444\n","torch.Size([10, 400, 1, 1])\n","torch.Size([10, 400, 1, 1])\n","torch.Size([10, 400, 1, 1])\n","torch.Size([3, 400, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0002_50.pth\n","torch.Size([9, 400, 1, 1])\n","Epoch: 2, Accuracy: 0.4444444444444444\n","torch.Size([10, 400, 1, 1])\n","torch.Size([10, 400, 1, 1])\n","torch.Size([10, 400, 1, 1])\n","torch.Size([3, 400, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0003_50.pth\n","torch.Size([9, 400, 1, 1])\n","Epoch: 3, Accuracy: 0.4444444444444444\n","torch.Size([10, 400, 1, 1])\n","torch.Size([10, 400, 1, 1])\n","torch.Size([10, 400, 1, 1])\n","torch.Size([3, 400, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0004_50.pth\n","torch.Size([9, 400, 1, 1])\n","Epoch: 4, Accuracy: 0.7777777777777778\n","torch.Size([10, 400, 1, 1])\n","torch.Size([10, 400, 1, 1])\n","torch.Size([10, 400, 1, 1])\n","torch.Size([3, 400, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0005_50.pth\n","torch.Size([9, 400, 1, 1])\n","Epoch: 5, Accuracy: 0.5555555555555556\n","torch.Size([10, 400, 1, 1])\n","torch.Size([10, 400, 1, 1])\n","torch.Size([10, 400, 1, 1])\n","torch.Size([3, 400, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0006_50.pth\n","torch.Size([9, 400, 1, 1])\n","Epoch: 6, Accuracy: 0.7777777777777778\n","torch.Size([10, 400, 1, 1])\n","torch.Size([10, 400, 1, 1])\n","torch.Size([10, 400, 1, 1])\n","torch.Size([3, 400, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0007_50.pth\n","torch.Size([9, 400, 1, 1])\n","Epoch: 7, Accuracy: 0.7777777777777778\n","torch.Size([10, 400, 1, 1])\n","torch.Size([10, 400, 1, 1])\n","torch.Size([10, 400, 1, 1])\n","torch.Size([3, 400, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0008_50.pth\n","torch.Size([9, 400, 1, 1])\n","Epoch: 8, Accuracy: 0.7777777777777778\n","torch.Size([10, 400, 1, 1])\n","torch.Size([10, 400, 1, 1])\n","torch.Size([10, 400, 1, 1])\n","torch.Size([3, 400, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0009_50.pth\n","torch.Size([9, 400, 1, 1])\n","Epoch: 9, Accuracy: 0.5555555555555556\n","torch.Size([10, 400, 1, 1])\n","torch.Size([10, 400, 1, 1])\n","torch.Size([10, 400, 1, 1])\n","torch.Size([3, 400, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0010_50.pth\n","torch.Size([9, 400, 1, 1])\n","Epoch: 10, Accuracy: 0.5555555555555556\n","Using 100 neurons\n","CREAR MODELO 100\n","torch.Size([10, 800, 1, 1])\n","torch.Size([10, 800, 1, 1])\n","torch.Size([10, 800, 1, 1])\n","torch.Size([3, 800, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0001_100.pth\n","torch.Size([9, 800, 1, 1])\n","Epoch: 1, Accuracy: 0.4444444444444444\n","torch.Size([10, 800, 1, 1])\n","torch.Size([10, 800, 1, 1])\n","torch.Size([10, 800, 1, 1])\n","torch.Size([3, 800, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0002_100.pth\n","torch.Size([9, 800, 1, 1])\n","Epoch: 2, Accuracy: 0.4444444444444444\n","torch.Size([10, 800, 1, 1])\n","torch.Size([10, 800, 1, 1])\n","torch.Size([10, 800, 1, 1])\n","torch.Size([3, 800, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0003_100.pth\n","torch.Size([9, 800, 1, 1])\n","Epoch: 3, Accuracy: 0.4444444444444444\n","torch.Size([10, 800, 1, 1])\n","torch.Size([10, 800, 1, 1])\n","torch.Size([10, 800, 1, 1])\n","torch.Size([3, 800, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0004_100.pth\n","torch.Size([9, 800, 1, 1])\n","Epoch: 4, Accuracy: 0.4444444444444444\n","torch.Size([10, 800, 1, 1])\n","torch.Size([10, 800, 1, 1])\n","torch.Size([10, 800, 1, 1])\n","torch.Size([3, 800, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0005_100.pth\n","torch.Size([9, 800, 1, 1])\n","Epoch: 5, Accuracy: 0.4444444444444444\n","torch.Size([10, 800, 1, 1])\n","torch.Size([10, 800, 1, 1])\n","torch.Size([10, 800, 1, 1])\n","torch.Size([3, 800, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0006_100.pth\n","torch.Size([9, 800, 1, 1])\n","Epoch: 6, Accuracy: 0.4444444444444444\n","torch.Size([10, 800, 1, 1])\n","torch.Size([10, 800, 1, 1])\n","torch.Size([10, 800, 1, 1])\n","torch.Size([3, 800, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0007_100.pth\n","torch.Size([9, 800, 1, 1])\n","Epoch: 7, Accuracy: 0.4444444444444444\n","torch.Size([10, 800, 1, 1])\n","torch.Size([10, 800, 1, 1])\n","torch.Size([10, 800, 1, 1])\n","torch.Size([3, 800, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0008_100.pth\n","torch.Size([9, 800, 1, 1])\n","Epoch: 8, Accuracy: 0.4444444444444444\n","torch.Size([10, 800, 1, 1])\n","torch.Size([10, 800, 1, 1])\n","torch.Size([10, 800, 1, 1])\n","torch.Size([3, 800, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0009_100.pth\n","torch.Size([9, 800, 1, 1])\n","Epoch: 9, Accuracy: 0.4444444444444444\n","torch.Size([10, 800, 1, 1])\n","torch.Size([10, 800, 1, 1])\n","torch.Size([10, 800, 1, 1])\n","torch.Size([3, 800, 1, 1])\n","Saved checkpoint into D:/Master/TFM/Checkpoints\\checkpoint_0010_100.pth\n","torch.Size([9, 800, 1, 1])\n","Epoch: 10, Accuracy: 0.4444444444444444\n","Best Accuracy: 0.8888888888888888\n","Best Parameters: {'num_neurons': 10}\n"]}],"source":["# Import necessary libraries\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import ParameterGrid\n","\n","# Convert lists to tensors\n","imagenes = torch.stack([torch.Tensor(i) for i in imagenes])\n","etiquetas = torch.tensor(listado_arrays_etiquetas)\n","\n","# Split data into training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(imagenes, etiquetas, test_size=0.2, random_state=42)\n","\n","# Define custom dataset\n","class CustomDataset(Dataset):\n","    def __init__(self, X, y):\n","        self.X = X\n","        self.y = y\n","\n","    def __len__(self):\n","        return len(self.X)\n","\n","    def __getitem__(self, idx):\n","        return self.X[idx], self.y[idx]\n","\n","# Create train and test datasets\n","train_dataset = CustomDataset(X_train, y_train)\n","test_dataset = CustomDataset(X_test, y_test)\n","\n","# Define the model architecture\n","class Model(nn.Module):\n","    def __init__(self, num_neurons):\n","        super(Model, self).__init__()\n","        self.conv1 = nn.Conv2d(3, num_neurons, 3)\n","        self.conv2 = nn.Conv2d(num_neurons, num_neurons*2, 3)\n","        self.conv3 = nn.Conv2d(num_neurons*2, num_neurons*4, 3)\n","        self.conv4 = nn.Conv2d(num_neurons*4, num_neurons*8, 3)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.fc1 = nn.Linear(num_neurons*8, num_neurons)  # Asume que después de cuatro convoluciones y max pooling, la dimensión es num_neurons * 8 * 3 * 3\n","        self.fc2 = nn.Linear(num_neurons, 1)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = self.pool(F.relu(self.conv2(x)))\n","        x = self.pool(F.relu(self.conv3(x)))\n","        x = self.pool(F.relu(self.conv4(x)))\n","        print(x.size())\n","        x = x.view(-1, self.num_flat_features(x))\n","        x = F.relu(self.fc1(x))\n","        x = self.sigmoid(self.fc2(x))\n","        return x\n","\n","    def num_flat_features(self, x):\n","        size = x.size()[1:]  # all dimensions except the batch dimension\n","        num_features = 1\n","        for s in size:\n","            num_features *= s\n","        return num_features\n","\n","# Define the function to create the model\n","def crear_modelo(num_neurons):\n","    print(\"CREAR MODELO\", num_neurons)\n","    model = Model(num_neurons)\n","    criterion = nn.BCELoss()\n","    optimizer = optim.Adam(model.parameters())\n","    return model, criterion, optimizer\n","\n","# Define the checkpoint directory\n","checkpoint_dir = 'D:/Master/TFM/Checkpoints'\n","\n","# Create checkpoint directory if it doesn't exist\n","os.makedirs(checkpoint_dir, exist_ok=True)\n","\n","def save_ckpt(model, optimizer, epoch, num_neurons, checkpoint_dir):\n","    save_dir = os.path.join(checkpoint_dir, \"checkpoint_{:04d}_{}.pth\".format(epoch, num_neurons))\n","\n","    cp = {\n","        'model': model.state_dict(),\n","        'optimizer': optimizer.state_dict(),\n","        'epoch': epoch,\n","    }\n","\n","    torch.save(cp, save_dir)\n","    print(\"Saved checkpoint into {}\".format(save_dir))\n","\n","\n","def load_ckpt(checkpoint_dir, num_neurons):\n","    last_epoch = 0\n","    checkpoint_file = ''\n","\n","    for file in os.listdir(checkpoint_dir):\n","        if file.endswith('{}.pth'.format(num_neurons)):\n","            epoch_number = int(file.split('_')[1])\n","            if epoch_number > last_epoch:\n","                last_epoch = epoch_number\n","                checkpoint_file = file\n","\n","    if last_epoch == 0:\n","        return None, 0\n","    else:\n","        print(\"Loaded checkpoint\", os.path.join(checkpoint_dir, checkpoint_file))\n","        checkpoint = torch.load(os.path.join(checkpoint_dir, checkpoint_file))\n","        return checkpoint, checkpoint['epoch']\n","\n","# Define the grid of parameters\n","param_grid = {\n","    'num_neurons': [10, 20, 30, 40, 50,100],\n","}\n","\n","# Perform grid search\n","best_accuracy = 0.0\n","best_params = None\n","\n","for params in ParameterGrid(param_grid):\n","    print(\"Using {} neurons\".format(params['num_neurons']))\n","    model, criterion, optimizer = crear_modelo(params['num_neurons'])\n","    checkpoint, start_epoch = load_ckpt(checkpoint_dir, params['num_neurons'])\n","    if checkpoint is not None:\n","        model.load_state_dict(checkpoint['model'])\n","        optimizer.load_state_dict(checkpoint['optimizer'])\n","\n","    train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n","    test_loader = DataLoader(test_dataset, batch_size=10, shuffle=False)\n","\n","    for epoch in range(start_epoch, start_epoch + 10):\n","        model.train()\n","        for inputs, labels in train_loader:\n","            optimizer.zero_grad()\n","            inputs = inputs.permute((0,3,1,2))\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels.float().unsqueeze(1))\n","            loss.backward()\n","            optimizer.step()\n","\n","        save_ckpt(model, optimizer, epoch + 1, params['num_neurons'], checkpoint_dir) # Save the checkpoint\n","\n","        model.eval()\n","        correct = 0\n","        total = 0\n","        with torch.no_grad():\n","            for inputs, labels in test_loader:\n","                inputs = inputs.permute((0,3,1,2))\n","                outputs = model(inputs)\n","                predicted = (outputs >= 0.5).squeeze().long()\n","                total += labels.size(0)\n","                correct += (predicted == labels).sum().item()\n","\n","        accuracy = correct / total\n","        print(\"Epoch: {}, Accuracy: {}\".format(epoch + 1, accuracy))\n","        if accuracy > best_accuracy:\n","            best_accuracy = accuracy\n","            best_params = params\n","\n","print(\"Best Accuracy:\", best_accuracy)\n","print(\"Best Parameters:\", best_params)\n"]},{"cell_type":"code","execution_count":null,"id":"b963f6f9","metadata":{"id":"b963f6f9"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}